{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrKdlNNBDco9"
      },
      "source": [
        "## Building a CNN to classify images in the CIFAR-10 Dataset\n",
        "\n",
        "We will work with the CIFAR-10 Dataset.  This is a well-known dataset for image classification, which consists of 60000 32x32 color images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
        "\n",
        "The 10 classes are:\n",
        "\n",
        "<ol start=\"0\">\n",
        "<li> airplane\n",
        "<li>  automobile\n",
        "<li> bird\n",
        "<li>  cat\n",
        "<li> deer\n",
        "<li> dog\n",
        "<li>  frog\n",
        "<li>  horse\n",
        "<li>  ship\n",
        "<li>  truck\n",
        "</ol>\n",
        "\n",
        "For details about CIFAR-10 see:\n",
        "https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "\n",
        "For a compilation of published performance results on CIFAR 10, see:\n",
        "http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html\n",
        "\n",
        "---\n",
        "\n",
        "### Building Convolutional Neural Nets\n",
        "\n",
        "In this exercise we will build and train our first convolutional neural networks.  In the first part, we walk through the different layers and how they are configured.  In the second part, you will build your own model, train it, and compare the performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R03rqrniDcpA"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cyXPYxNDcpC",
        "outputId": "e5ffe5d9-bd16-43ab-a277-16f42b56c4a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ],
      "source": [
        "# The data, shuffled and split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQ8L0ZtqDcpD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e90cc3bb-3284-4022-9bb5-55fd9f1cfc63"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "## Each image is a 32 x 32 x 3 numpy array\n",
        "x_train[444].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htn1fF8zDcpD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "89dc2aba-47bc-452c-9163-b0c4b1d921a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "## Let's look at one of the images\n",
        "\n",
        "print(y_train[444])\n",
        "plt.imshow(x_train[444]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "AqGwvm1vDcpD"
      },
      "outputs": [],
      "source": [
        "num_classes = 10\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHUAE0hVDcpE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "736f9c29-4fba-4863-c377-ceda56f26430"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# now instead of classes described by an integer between 0-9 we have a vector with a 1 in the (Pythonic) 9th position\n",
        "y_train[444]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "zdHoHbykDcpE"
      },
      "outputs": [],
      "source": [
        "# As before, let's make everything float and scale\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zippHBoVDcpF"
      },
      "source": [
        "## Keras Layers for CNNs\n",
        "- Previously we built Neural Networks using primarily the Dense, Activation and Dropout Layers.\n",
        "\n",
        "- Here we will describe how to use some of the CNN-specific layers provided by Keras\n",
        "\n",
        "### Conv2D\n",
        "\n",
        "```python\n",
        "keras.layers.convolutional.Conv2D(filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n",
        "```\n",
        "\n",
        "A few parameters explained:\n",
        "- `filters`: the number of filter used per location.  In other words, the depth of the output.\n",
        "- `kernel_size`: an (x,y) tuple giving the height and width of the kernel to be used\n",
        "- `strides`: and (x,y) tuple giving the stride in each dimension.  Default is `(1,1)`\n",
        "- `input_shape`: required only for the first layer\n",
        "\n",
        "Note, the size of the output will be determined by the kernel_size, strides\n",
        "\n",
        "### MaxPooling2D\n",
        "`keras.layers.pooling.MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None)`\n",
        "\n",
        "- `pool_size`: the (x,y) size of the grid to be pooled.\n",
        "- `strides`: Assumed to be the `pool_size` unless otherwise specified\n",
        "\n",
        "### Flatten\n",
        "Turns its input into a one-dimensional vector (per instance).  Usually used when transitioning between convolutional layers and fully connected layers.\n",
        "\n",
        "---\n",
        "\n",
        "## First CNN\n",
        "Below we will build our first CNN.  For demonstration purposes (so that it will train quickly) it is not very deep and has relatively few parameters.  We use strides of 2 in the first two convolutional layers which quickly reduces the dimensions of the output.  After a MaxPooling layer, we flatten, and then have a single fully connected layer before our final classification layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALA6XCG3DcpF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "outputId": "e4f58db8-44d9-4402-8ff4-d06cd9823fec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m2,432\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │        \u001b[38;5;34m25,632\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m147,968\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m5,130\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,432</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">25,632</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,968</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m181,162\u001b[0m (707.66 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">181,162</span> (707.66 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m181,162\u001b[0m (707.66 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">181,162</span> (707.66 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Let's build a CNN using Keras' Sequential capabilities\n",
        "\n",
        "model_1 = Sequential()\n",
        "\n",
        "\n",
        "## 5x5 convolution with 2x2 stride and 32 filters\n",
        "model_1.add(Conv2D(32, kernel_size = (5, 5), strides = (2,2), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model_1.add(Activation('relu'))\n",
        "\n",
        "## Another 5x5 convolution with 2x2 stride and 32 filters\n",
        "model_1.add(Conv2D(32, (5, 5), strides = (2,2), activation=\"relu\")) # another way to define activation\n",
        "\n",
        "\n",
        "## 2x2 max pooling reduces to 3 x 3 x 32\n",
        "model_1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_1.add(Dropout(0.25))\n",
        "\n",
        "## Flatten turns 3x3x32 into 288x1\n",
        "model_1.add(Flatten())\n",
        "model_1.add(Dense(512))\n",
        "model_1.add(Activation('relu'))\n",
        "model_1.add(Dropout(0.5))\n",
        "model_1.add(Dense(num_classes))\n",
        "model_1.add(Activation('softmax'))\n",
        "\n",
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqrOZtoWDcpG"
      },
      "source": [
        "We still have 181K parameters, even though this is a \"small\" model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUFhWfGIDcpG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccf93f66-d61d-4e54-c706-2e0488af3264"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.3136 - loss: 1.8675 - val_accuracy: 0.4506 - val_loss: 1.5152\n",
            "Epoch 2/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.4739 - loss: 1.4538 - val_accuracy: 0.5385 - val_loss: 1.2852\n",
            "Epoch 3/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5191 - loss: 1.3548 - val_accuracy: 0.5606 - val_loss: 1.2484\n",
            "Epoch 4/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5435 - loss: 1.3027 - val_accuracy: 0.5620 - val_loss: 1.2574\n",
            "Epoch 5/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5592 - loss: 1.2648 - val_accuracy: 0.5616 - val_loss: 1.2314\n",
            "Epoch 6/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5674 - loss: 1.2424 - val_accuracy: 0.5452 - val_loss: 1.3458\n",
            "Epoch 7/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.5718 - loss: 1.2406 - val_accuracy: 0.5917 - val_loss: 1.1967\n",
            "Epoch 8/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5748 - loss: 1.2402 - val_accuracy: 0.6114 - val_loss: 1.1200\n",
            "Epoch 9/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5711 - loss: 1.2464 - val_accuracy: 0.5790 - val_loss: 1.2071\n",
            "Epoch 10/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.5820 - loss: 1.2403 - val_accuracy: 0.4886 - val_loss: 1.5045\n",
            "Epoch 11/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5753 - loss: 1.2391 - val_accuracy: 0.6053 - val_loss: 1.1649\n",
            "Epoch 12/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.5779 - loss: 1.2530 - val_accuracy: 0.5396 - val_loss: 1.3305\n",
            "Epoch 13/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5763 - loss: 1.2622 - val_accuracy: 0.5561 - val_loss: 1.2769\n",
            "Epoch 14/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5788 - loss: 1.2512 - val_accuracy: 0.5679 - val_loss: 1.2698\n",
            "Epoch 15/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5731 - loss: 1.2575 - val_accuracy: 0.5863 - val_loss: 1.2251\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b0b01452b50>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "batch_size = 32\n",
        "\n",
        "# initiate RMSprop optimizer\n",
        "opt = keras.optimizers.RMSprop(learning_rate=0.0005)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model_1.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_1.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=15,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "PQptzKUXDcpG"
      },
      "source": [
        "### Exercise\n",
        "Our previous model had the structure:\n",
        "\n",
        "Conv -> Conv -> MaxPool -> (Flatten) -> Dense -> Final Classification\n",
        "\n",
        "(with appropriate activation functions and dropouts)\n",
        "\n",
        "1. Build a more complicated model with the following pattern:\n",
        "- Conv -> Conv -> MaxPool -> Conv -> Conv -> MaxPool -> (Flatten) -> Dense -> Final Classification\n",
        "\n",
        "- Use strides of 1 for all convolutional layers.\n",
        "\n",
        "2. How many parameters does your model have?  How does that compare to the previous model?\n",
        "\n",
        "3. Train it for 5 epochs.  What do you notice about the training time, loss and accuracy numbers (on both the training and validation sets)?\n",
        "\n",
        "5. Try different structures and run times, and see how accurate your model can be.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "HLLkWOQ9DcpG"
      },
      "outputs": [],
      "source": [
        "# Please provide your solution here\n",
        "# Create model_2 as mentioned in the exercise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "NZQW-T8EDcpH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classifying CIFAR-10 with Data Augmentation\n",
        "\n",
        "Data augmentation is used to artificially expand your training dataset by creating modified versions of existing images.\n",
        "\n",
        "These modifications help your model become more robust, generalize better, and avoid overfitting.\n",
        "\n",
        "Next, we revisit CIFAR-10 and the networks we previously built.  We will use real-time data augmentation to try to improve our results.\n",
        "\n",
        "When you are done going through the notebook, experiment with different data augmentation parameters and see if they help (or hurt!) the performance of your classifier."
      ],
      "metadata": {
        "id": "94ew2QR_HRFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "    horizontal_flip=False,  # randomly flip images\n",
        "    shear_range=0.1,   # Shear intensity (shear angle in counter-clockwise direction)\n",
        "    zoom_range=0.1,    # Zoom in/out on images\n",
        "    fill_mode='nearest'   # Strategy to fill in new pixels\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "Qsw9m0n5HRZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's build a CNN using Keras' Sequential capabilities\n",
        "model_1 = Sequential()\n",
        "\n",
        "## 5x5 convolution with 2x2 stride and 32 filters\n",
        "model_1.add(Conv2D(32, kernel_size = (5, 5), strides = (2,2), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model_1.add(Activation('relu'))\n",
        "\n",
        "## Another 5x5 convolution with 2x2 stride and 32 filters\n",
        "model_1.add(Conv2D(32, (5, 5), strides = (2,2), activation=\"relu\")) # another way to define activation\n",
        "\n",
        "\n",
        "## 2x2 max pooling reduces to 3 x 3 x 32\n",
        "model_1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#model_1.add(Dropout(0.25))\n",
        "\n",
        "## Flatten turns 3x3x32 into 288x1\n",
        "model_1.add(Flatten())\n",
        "model_1.add(Dense(512))\n",
        "model_1.add(Activation('relu'))\n",
        "#model_1.add(Dropout(0.5))\n",
        "model_1.add(Dense(num_classes))\n",
        "model_1.add(Activation('softmax'))\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model_1.compile(loss='categorical_crossentropy',\n",
        "                optimizer='rmsprop',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# Fit the model on the batches generated by datagen.flow().\n",
        "model_1.fit(\n",
        "    datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "    epochs=15,\n",
        "    validation_data=(x_test, y_test)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhZCfctiJM6y",
        "outputId": "2c09aeae-a0bf-4017-e2c7-1ac4a745a482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 20ms/step - accuracy: 0.3195 - loss: 1.8580 - val_accuracy: 0.5205 - val_loss: 1.3476\n",
            "Epoch 2/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.4840 - loss: 1.4376 - val_accuracy: 0.5217 - val_loss: 1.3634\n",
            "Epoch 3/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.5274 - loss: 1.3324 - val_accuracy: 0.5750 - val_loss: 1.1765\n",
            "Epoch 4/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.5594 - loss: 1.2471 - val_accuracy: 0.6083 - val_loss: 1.1206\n",
            "Epoch 5/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.5745 - loss: 1.2118 - val_accuracy: 0.6015 - val_loss: 1.1356\n",
            "Epoch 6/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 19ms/step - accuracy: 0.5858 - loss: 1.1726 - val_accuracy: 0.6154 - val_loss: 1.1121\n",
            "Epoch 7/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 19ms/step - accuracy: 0.6007 - loss: 1.1575 - val_accuracy: 0.6197 - val_loss: 1.0995\n",
            "Epoch 8/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.6035 - loss: 1.1363 - val_accuracy: 0.6273 - val_loss: 1.0985\n",
            "Epoch 9/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 19ms/step - accuracy: 0.6074 - loss: 1.1399 - val_accuracy: 0.6604 - val_loss: 0.9989\n",
            "Epoch 10/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.6181 - loss: 1.1066 - val_accuracy: 0.6279 - val_loss: 1.1005\n",
            "Epoch 11/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.6132 - loss: 1.1133 - val_accuracy: 0.6527 - val_loss: 1.0322\n",
            "Epoch 12/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.6201 - loss: 1.1032 - val_accuracy: 0.6485 - val_loss: 1.0506\n",
            "Epoch 13/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.6232 - loss: 1.1023 - val_accuracy: 0.6452 - val_loss: 1.0841\n",
            "Epoch 14/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.6258 - loss: 1.0899 - val_accuracy: 0.6548 - val_loss: 1.0765\n",
            "Epoch 15/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 19ms/step - accuracy: 0.6221 - loss: 1.1078 - val_accuracy: 0.6285 - val_loss: 1.0848\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b0b01450390>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How does the performance compare with the non-augmented training?"
      ],
      "metadata": {
        "id": "y2C-vugZIfVt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4fZEvm8XIwyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "X7G6uy0aGIh0"
      },
      "source": [
        "## Exercise\n",
        "### Your Turn\n",
        "\n",
        "1. Experiment above with different settings of the data augmentation parameters.  Can you make the model do better?  Can you make it do worse?\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}